const e=JSON.parse(`{"key":"v-019d0df5","path":"/deeplearning/ddp.html","title":"DDP Test","lang":"zh-CN","frontmatter":{"icon":"edit","date":"2022-07-11T00:00:00.000Z","category":["深度学习"],"tag":["DDP"],"description":"DDP Test DDP每张卡计算特征 把每张卡返回的结果进行gather，返回List列表 把gather的结果放在主卡用于指标评估 gather代码如下： def all_gather(data): \\"\\"\\" Run all_gather on arbitrary picklable data (not necessarily tensors) Args: data: any picklable object Returns: list[data]: list of data gathered from each rank \\"\\"\\" world_size = comm.world_size if world_size == 1: return [data] # serialized to a Tensor buffer = pickle.dumps(data) storage = torch.ByteStorage.from_buffer(buffer) tensor = torch.ByteTensor(storage).to(\\"cuda\\") # obtain Tensor size of each rank local_size = torch.LongTensor([tensor.numel()]).to(\\"cuda\\") size_list = [torch.LongTensor([0]).to(\\"cuda\\") for _ in range(world_size)] dist.all_gather(size_list, local_size) size_list = [int(size.item()) for size in size_list] max_size = max(size_list) # receiving Tensor from all ranks # we pad the tensor because torch all_gather does not support # gathering tensors of different shapes tensor_list = [] for _ in size_list: tensor_list.append(torch.ByteTensor(size=(max_size,)).to(\\"cuda\\")) if local_size != max_size: padding = torch.ByteTensor(size=(max_size - local_size,)).to(\\"cuda\\") tensor = torch.cat((tensor, padding), dim=0) dist.all_gather(tensor_list, tensor) data_list = [] for size, tensor in zip(size_list, tensor_list): buffer = tensor.cpu().numpy().tobytes()[:size] data_list.append(pickle.loads(buffer)) return data_list","head":[["meta",{"property":"og:url","content":"https://leijue222.github.io/deeplearning/ddp.html"}],["meta",{"property":"og:site_name","content":"Yuze's Blog"}],["meta",{"property":"og:title","content":"DDP Test"}],["meta",{"property":"og:description","content":"DDP Test DDP每张卡计算特征 把每张卡返回的结果进行gather，返回List列表 把gather的结果放在主卡用于指标评估 gather代码如下： def all_gather(data): \\"\\"\\" Run all_gather on arbitrary picklable data (not necessarily tensors) Args: data: any picklable object Returns: list[data]: list of data gathered from each rank \\"\\"\\" world_size = comm.world_size if world_size == 1: return [data] # serialized to a Tensor buffer = pickle.dumps(data) storage = torch.ByteStorage.from_buffer(buffer) tensor = torch.ByteTensor(storage).to(\\"cuda\\") # obtain Tensor size of each rank local_size = torch.LongTensor([tensor.numel()]).to(\\"cuda\\") size_list = [torch.LongTensor([0]).to(\\"cuda\\") for _ in range(world_size)] dist.all_gather(size_list, local_size) size_list = [int(size.item()) for size in size_list] max_size = max(size_list) # receiving Tensor from all ranks # we pad the tensor because torch all_gather does not support # gathering tensors of different shapes tensor_list = [] for _ in size_list: tensor_list.append(torch.ByteTensor(size=(max_size,)).to(\\"cuda\\")) if local_size != max_size: padding = torch.ByteTensor(size=(max_size - local_size,)).to(\\"cuda\\") tensor = torch.cat((tensor, padding), dim=0) dist.all_gather(tensor_list, tensor) data_list = [] for size, tensor in zip(size_list, tensor_list): buffer = tensor.cpu().numpy().tobytes()[:size] data_list.append(pickle.loads(buffer)) return data_list"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-04-06T03:46:06.000Z"}],["meta",{"property":"article:author","content":"Yuze"}],["meta",{"property":"article:tag","content":"DDP"}],["meta",{"property":"article:published_time","content":"2022-07-11T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-04-06T03:46:06.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"DDP Test\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-07-11T00:00:00.000Z\\",\\"dateModified\\":\\"2023-04-06T03:46:06.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Yuze\\",\\"url\\":\\"https://leijue222.github.io/\\"}]}"]]},"headers":[],"git":{"createdTime":1680752766000,"updatedTime":1680752766000,"contributors":[{"name":"leijue222","email":"dyw222@foxmail.com","commits":1}]},"readingTime":{"minutes":0.71,"words":214},"filePathRelative":"deeplearning/ddp.md","localizedDate":"2022年7月11日","excerpt":"<h1> DDP Test</h1>\\n<ol>\\n<li>DDP每张卡计算特征</li>\\n<li>把每张卡返回的结果进行gather，返回List列表</li>\\n<li>把gather的结果放在主卡用于指标评估</li>\\n</ol>\\n<p>gather代码如下：</p>\\n<div class=\\"language-text line-numbers-mode\\" data-ext=\\"text\\"><pre class=\\"language-text\\"><code>def all_gather(data):\\n    \\"\\"\\"\\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\\n    Args:\\n        data: any picklable object\\n    Returns:\\n        list[data]: list of data gathered from each rank\\n    \\"\\"\\"\\n    world_size = comm.world_size\\n    if world_size == 1:\\n        return [data]\\n\\n    # serialized to a Tensor\\n    buffer = pickle.dumps(data)\\n    storage = torch.ByteStorage.from_buffer(buffer)\\n    tensor = torch.ByteTensor(storage).to(\\"cuda\\")\\n\\n    # obtain Tensor size of each rank\\n    local_size = torch.LongTensor([tensor.numel()]).to(\\"cuda\\")\\n    size_list = [torch.LongTensor([0]).to(\\"cuda\\") for _ in range(world_size)]\\n    dist.all_gather(size_list, local_size)\\n    size_list = [int(size.item()) for size in size_list]\\n    max_size = max(size_list)\\n\\n    # receiving Tensor from all ranks\\n    # we pad the tensor because torch all_gather does not support\\n    # gathering tensors of different shapes\\n    tensor_list = []\\n    for _ in size_list:\\n        tensor_list.append(torch.ByteTensor(size=(max_size,)).to(\\"cuda\\"))\\n    if local_size != max_size:\\n        padding = torch.ByteTensor(size=(max_size - local_size,)).to(\\"cuda\\")\\n        tensor = torch.cat((tensor, padding), dim=0)\\n    dist.all_gather(tensor_list, tensor)\\n\\n    data_list = []\\n    for size, tensor in zip(size_list, tensor_list):\\n        buffer = tensor.cpu().numpy().tobytes()[:size]\\n        data_list.append(pickle.loads(buffer))\\n\\n    return data_list\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{e as data};
